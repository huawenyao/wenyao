
工具 速度 数据方向 开源 GUI 支持表构建 二进制数据 支持增量 批量操作
kettle  多种（大数据和RDBMS）->多种 √ √ √   
DataX 单机2W/s不支持集群 多种->多种 √ × 不支持   不支持
DataHub        
dbsync  2000/s RDBMS  √ 支持   支持
Sqoop √ 大数据->RDBMS，RDBMS->大数据 √ ×    
Streamsets √ 多种->多种 √ √    
Informatica √ 多种->多种 × √    
Talend √ 多种->多种 √ √    
DataPipeline √ 多种->多种 × √    
datastage √ 多种->多种 × √    
ODI √ 多种->多种 × √    
dbswitch 10W/s RDMS √ × ×   支持
 一、背景
      开源MPP数据库Greenplum是一种基于PostgreSQL的分布式数据库，其采用shared-nothing架构，其架构专门用于管理大规模分析数据仓库，Greenplum主要定位在OLAP领域，利用Greenplum MPP数据库做大数据计算或分析平台非常适合，典型的就是数据仓库系统。
     虽然Greenplum支持JDBC 、libpg、copy、gpfdist等多种方式加载数据。但是通常的业务系统中的数据存储往往是MySQL、Oracle、SQLServer、PostegreSQL等数据库。要想把这些数据库中的数据导入至Greenplum数据库中，需要借助一定的（离线同步）工具，典型的工具包括：
    （1）利用kettle+gpload工具
        优点：工具开源且现成，导入速度快，kettle支持表结构同步和表数据同步；
        缺点：gpload配置过于复杂，kettle功能多，学习成本高，每张表都需要单独配置，不适用于大批量表的操作；
   （2）使用Greenplum工具gpfdist或外部表方式
      优点：导入速度快
      缺点：需要先将MySQL、Oracle、SQLServer、PostegreSQL等数据库内的数据导出为文本文件，同样不适用于大批量表的操作；
    （3）datax工具
      优点：工具现成，支持插件扩展；
      缺点：不支持表结构同步，需要人工参与目的端表的创建；
     地址：https://github.com/alibaba/DataX
   （4）dbsync 工具
     优点：支持表结构与数据的同步；
     缺点：同步千万级数据量时会OOM、对于含有大小写的表名或字段名进行DDL转换存在问题、只支持MySQL/PostgreSQL到Greenplum/PostgreSQL的表结构与数据同步同步等等，其他问题请参考issue：https://github.com/aliyun/rds_dbsync/issues
   地址：https://github.com/aliyun/rds_dbsync
二、dbswitch工具
    结合kettle的表结构同步功能及网上高僧基于copy方式改良的datax，dbswitch提供常见的oracle/SqlServer/mysql/PostgreSQL向Greenplum数据库的表结构及数据同步功能。功能点如下：
表（视图）结构向GP转换及在GP中自动建表；
表数据抽取至GP数据库中；
支持同一schema下的多张表同步；
提供RESTfull的表结构转换服务接口；
  项目地址：https://gitee.com/inrgihc/dbswitch
工具缺点：
不支持二进制字段数据的数据抽取同步；
当前为单线程处理，并发同步有待提高；
对于GP建表时未考虑分布式键问题

 
DataX：
1.使用在hadoop时，如果文件过大，作为源端数据导入目标数据库时会有数据缺失；
2.datax往gp中写数最好使用gp的writer方式，否则会很慢。
 
Kettle:
性能较DataX等较差。
 
Datastage和Informatica商业，功能完备，市场占有率高。
 
ODI：oracle耦合度高。
 
Sqoop和Streamsets更适用于大数据相关的数据源。
 
Talend:开源版没有调度程序，且后续的维护运维成本高，建议商业版。按照用户数收费，开发用户多不合算。

 ETL的元数据包括数据源、目标数据的结构、转换规则以及过程的依赖关系等。在这方面，Datastage和Powercenter从功能上看可谓不分伯仲，只是后者的元数据更加开放，存放在关系数据库中，可以很容易被访问（Informatic把Metadata全部放在数据库中而Datastage是自己管理Metadata，不依赖任何数据库.）。此外，这两个厂家又同时提供专门的元数据管理工具，Ascential有Metastage，而Informatica拥有Superglue。你看，就不给你全部功能，变着法子从你口袋里面多掏点钱。
数据质量方面，两种产品都采用同样的策略——独立出ETL产品之外，另外有专门的数据质量管理产品。例如和Datastage配套用的有ProfileStage和QualityStage，而Informatica最近也索性收购了原先OEM的数据质量管理产品FirstLogic。而在它们的ETL产品中，只是在Job或是Session前后留下接口，所谓前过程、后过程，虽然不是专为数据质量预留的接口，不过至少可以利用它外挂一些数据质量控制的模块。
在具体实现上看，Datastage通过Job实现一个ETL过程，运行时可以通过指定不同参数运行多个实例。Powercenter通过Mapping表示一个ETL过程，运行时为Session，绑定了具体的物理数据文件或表。在修改维护上，这两个工具都是提供图形化界面。这样的好处是直观、傻瓜式的；不好的地方就是改动还是比较费事（特别是批量化的修改）。
定制开发方面，两者都提供抽取、转换插件的定制，但笔者认为，Datastage的定制开发性要比Powercenter要强那么一点点。因为Datastage至少还内嵌一种类BASIC语言，可以写一段批处理程序来增加灵活性，而Powercenter似乎还缺乏这类机制。另外从参数控制上，虽然两者的参数传递都是比较混乱的，但Datastage至少可以对每个job设定参数，并且可以job内部引用这个参数名；而Powercenter显得就有些偷懒，参数放在一个参数文件中，理论上的确可以灵活控制参数，但这个灵活性需要你自己更新文件中的参数值（例如日期更新）。另外，Powercenter还不能在mapping或session中引用参数名，这一点就让人恼火。


ETL工具选型参照表   
工具  优点 缺点
主流工具 Datastage 内嵌一种类BASIC语言，可通过批处理程序增加灵活性，可对每个job设定参数并在job内部引用 早期版本对流程支持缺乏考虑；图形化界面改动费事
 Powercenter 元数据管理更为开放，存放在关系数据库中，可以很容易被访问 没有内嵌类BASIC语言，参数值需人为更新，且不能引用参数名；图形化界面改动费事
 Automation 提供一套ETL框架，利用Teradata数据仓库本身的并行处理能力 对数据库依赖性强，选型时需要考虑综合成本（包括数据库等）
 udis睿智ETL 适合国内需求，性价比高 配置复杂，缺少对元数据的管理
自主开发  相对于购买主流ETL工具，成本较低 各种语言混杂开发，无架构可言，后期维护难度大。
